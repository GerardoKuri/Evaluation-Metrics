# Evaluation-Metrics
Repository dedicated for people to seek to evaluate errors between two numeric arrays in most cases and to evaluate confusion matrices.

This repository includes errors like:
-Mean Absolute Error
https://www.statisticshowto.com/absolute-error/

-Log Cosine Hyperbolic Loss
https://stats.stackexchange.com/questions/464354/when-is-log-cosh-loss-used

-Mean Squared Error
https://www.statisticshowto.com/probability-and-statistics/statistics-definitions/mean-squared-error/

-Root Mean Squared Error
https://www.statisticshowto.com/probability-and-statistics/regression-analysis/rmse-root-mean-square-error/

-Root Mean Squared Log Error
https://stats.stackexchange.com/questions/56658/how-do-you-interpret-rmsle-root-mean-squared-logarithmic-error


Evaluation of a confusion matrix to calculate:
-Precision

-Accuracy
https://www.forecast.app/faqs/what-is-the-difference-between-accuracy-and-precision

-F1-Score
https://towardsdatascience.com/the-f1-score-bec2bbc38aa6

-Sensitivity
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2636062/

And includes min max normalization for arrays too.
https://towardsdatascience.com/everything-you-need-to-know-about-min-max-normalization-in-python-b79592732b79
